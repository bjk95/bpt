{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()   \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/bpt-HHxo9gCA-py3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input.txt'"
     ]
    }
   ],
   "source": [
    "with open('input.txt', 'r', encoding='utf8') as f:\n",
    "    text = f.read()   \n",
    "\n",
    "print(f'{len(text)=}')\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "V=65\n"
     ]
    }
   ],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "V = len(characters)\n",
    "print(''.join(characters))\n",
    "print(f'{V=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brad'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {ch: i for i, ch in enumerate(characters)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "r = encode('Brad')\n",
    "decode(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mencode\u001b[49m(text), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m data[:\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encode' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(f'{data.dtype=}, {data.shape=}')\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split = int(len(data) *.9)\n",
    "train = data[:n_split]\n",
    "val = data[n_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 8\n",
    "train[:context_length+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when the input is tensor([18]), the target is 47\n",
      "when the input is tensor([18, 47]), the target is 56\n",
      "when the input is tensor([18, 47, 56]), the target is 57\n",
      "when the input is tensor([18, 47, 56, 57]), the target is 58\n",
      "when the input is tensor([18, 47, 56, 57, 58]), the target is 1\n",
      "when the input is tensor([18, 47, 56, 57, 58,  1]), the target is 15\n",
      "when the input is tensor([18, 47, 56, 57, 58,  1, 15]), the target is 47\n",
      "when the input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), the target is 58\n",
      "x=tensor([18, 47, 56, 57, 58,  1, 15, 47]), y=tensor([47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "x = train[:context_length]\n",
    "y = train[1:context_length+1]\n",
    "\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'when the input is {context}, the target is {target}')\n",
    "\n",
    "print(f'{x=}, {y=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch.shape=torch.Size([4, 8])\n",
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n",
      "Y_batch.shape=torch.Size([4, 8])\n",
      "tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0]])\n",
      "When the input is tensor([53]) the target is 59: b=0\n",
      "When the input is tensor([53, 59]) the target is 6: b=0\n",
      "When the input is tensor([53, 59,  6]) the target is 1: b=0\n",
      "When the input is tensor([53, 59,  6,  1]) the target is 58: b=0\n",
      "When the input is tensor([53, 59,  6,  1, 58]) the target is 56: b=0\n",
      "When the input is tensor([53, 59,  6,  1, 58, 56]) the target is 47: b=0\n",
      "When the input is tensor([53, 59,  6,  1, 58, 56, 47]) the target is 40: b=0\n",
      "When the input is tensor([53, 59,  6,  1, 58, 56, 47, 40]) the target is 59: b=0\n",
      "When the input is tensor([49]) the target is 43: b=1\n",
      "When the input is tensor([49, 43]) the target is 43: b=1\n",
      "When the input is tensor([49, 43, 43]) the target is 54: b=1\n",
      "When the input is tensor([49, 43, 43, 54]) the target is 1: b=1\n",
      "When the input is tensor([49, 43, 43, 54,  1]) the target is 47: b=1\n",
      "When the input is tensor([49, 43, 43, 54,  1, 47]) the target is 58: b=1\n",
      "When the input is tensor([49, 43, 43, 54,  1, 47, 58]) the target is 1: b=1\n",
      "When the input is tensor([49, 43, 43, 54,  1, 47, 58,  1]) the target is 58: b=1\n",
      "When the input is tensor([13]) the target is 52: b=2\n",
      "When the input is tensor([13, 52]) the target is 45: b=2\n",
      "When the input is tensor([13, 52, 45]) the target is 43: b=2\n",
      "When the input is tensor([13, 52, 45, 43]) the target is 50: b=2\n",
      "When the input is tensor([13, 52, 45, 43, 50]) the target is 53: b=2\n",
      "When the input is tensor([13, 52, 45, 43, 50, 53]) the target is 8: b=2\n",
      "When the input is tensor([13, 52, 45, 43, 50, 53,  8]) the target is 0: b=2\n",
      "When the input is tensor([13, 52, 45, 43, 50, 53,  8,  0]) the target is 26: b=2\n",
      "When the input is tensor([1]) the target is 39: b=3\n",
      "When the input is tensor([ 1, 39]) the target is 1: b=3\n",
      "When the input is tensor([ 1, 39,  1]) the target is 46: b=3\n",
      "When the input is tensor([ 1, 39,  1, 46]) the target is 53: b=3\n",
      "When the input is tensor([ 1, 39,  1, 46, 53]) the target is 59: b=3\n",
      "When the input is tensor([ 1, 39,  1, 46, 53, 59]) the target is 57: b=3\n",
      "When the input is tensor([ 1, 39,  1, 46, 53, 59, 57]) the target is 43: b=3\n",
      "When the input is tensor([ 1, 39,  1, 46, 53, 59, 57, 43]) the target is 0: b=3\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "context_length = 8\n",
    "\n",
    "def get_batch(split:str = 'train') -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    data = train if split == 'train' else val\n",
    "    idx = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_length] for i in idx])\n",
    "    y = torch.stack([data[i+1:i+context_length+1] for i in idx])\n",
    "    return x, y\n",
    "\n",
    "X_batch, Y_batch = get_batch()\n",
    "print(f'{X_batch.shape=}\\n{X_batch[:10]}')\n",
    "print(f'{Y_batch.shape=}\\n{Y_batch[:10]}')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(context_length):\n",
    "        context = X_batch[b, :t+1]\n",
    "        target = Y_batch[b, t]\n",
    "        print(f'When the input is {context} the target is {target}: {b=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'V' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m             indicies \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((indicies, next_index), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m indicies\n\u001b[0;32m---> 34\u001b[0m m \u001b[38;5;241m=\u001b[39m BigramLanguageModel(\u001b[43mV\u001b[49m)\n\u001b[1;32m     35\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m m(X_batch, Y_batch)\n\u001b[1;32m     36\u001b[0m logits\u001b[38;5;241m.\u001b[39mshape, loss\n",
      "\u001b[0;31mNameError\u001b[0m: name 'V' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int) -> None:\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx: torch.Tensor, targets: torch.Tensor | None = None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batches, time_steps, channels = logits.shape\n",
    "            logits = logits.view(batches * time_steps, channels)\n",
    "            targets = targets.view(batches* time_steps)\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "        return logits, loss\n",
    "\n",
    "    \n",
    "    def generate(self, indicies: torch.Tensor, max_new_tokens: int):\n",
    "        for i in range(max_new_tokens):\n",
    "            logits, loss = self(indicies)\n",
    "            # extract last time step\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            next_index = torch.multinomial(probs,num_samples=1)\n",
    "            indicies = torch.cat((indicies, next_index), dim=1)\n",
    "            \n",
    "        return indicies\n",
    "    \n",
    "m = BigramLanguageModel(V)\n",
    "logits, loss = m(X_batch, Y_batch)\n",
    "logits.shape, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nBALLOUCoord'rer H:\\nICAd t gs trtin s: Twathy sthimbe wine k u h f h ff s t, s ayo be.\\nANos tcroll tovaspthis ar w mis y his Himayo Gotesith sownorthe:\\nFRDin fore po whand.\\nCin metis o, thend s t s prthinthyofan:\\nWef, dreadek w.\\nAnoyer'ditoby; thy geak awit t. My brito orthy httagerp ansensthart cery by,\\nLENThas whelllkes the wat w'sthe thie douswe t ser e ba ort ppe Har unden\\nI at, swhos.\\nGLABel\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=400)[0].tolist())\n",
    "# m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps=0 loss=tensor(2.4163, grad_fn=<NllLossBackward0>)\n",
      "steps=1000 loss=tensor(2.4161, grad_fn=<NllLossBackward0>)\n",
      "steps=2000 loss=tensor(2.5657, grad_fn=<NllLossBackward0>)\n",
      "steps=3000 loss=tensor(2.4316, grad_fn=<NllLossBackward0>)\n",
      "steps=4000 loss=tensor(2.5484, grad_fn=<NllLossBackward0>)\n",
      "steps=5000 loss=tensor(2.4627, grad_fn=<NllLossBackward0>)\n",
      "steps=6000 loss=tensor(2.4249, grad_fn=<NllLossBackward0>)\n",
      "steps=7000 loss=tensor(2.3524, grad_fn=<NllLossBackward0>)\n",
      "steps=8000 loss=tensor(2.4860, grad_fn=<NllLossBackward0>)\n",
      "steps=9000 loss=tensor(2.4564, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    X_batch, Y_batch = get_batch('train')\n",
    "    \n",
    "    logits, loss = m(X_batch, Y_batch)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if steps % 1000 == 0:\n",
    "        print(f'{steps=} {loss=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GARTH:\n",
      "Oh dear son, why hath thou sainters forsaken us?\n",
      "\n",
      "BRAD:\n",
      "Because thy sainters are destined to despair. Despair for thee supporters and thy foes.\n",
      "\n",
      "GARTH:\n",
      "Thy foes shalt not despair. For they are those whomst benefit from thy despair.\n",
      "\n",
      "BRAD:\n",
      "God let gentlemen eyes,\n",
      "But walk let we desire such my soul blesser,\n",
      "Which some than to kill, scare but the very preceived\n",
      "To hope in the vow'd dring for me, and patry this.\n",
      "\n",
      "BENVOLIO:\n",
      "Good will. The lark of God, that becomes him,\n",
      "And as hope him these have blood of love,\n",
      "Grace ungisters are Edward's children.\n",
      "The lies later hear two thee, before a gain.\n",
      "\n",
      "KING RICHARD III:\n",
      "A life hear o' the desir\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from gpt import NanoGPT\n",
    "import os\n",
    "\n",
    "os.chdir('/home/brad/dev/bpt/bpt/kapathy_videos/gpt')\n",
    "\n",
    "def generate_from_checkpoint(prefix_text, checkpoint_path, max_tokens=400):\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    \n",
    "    # Get character mappings\n",
    "    characters = checkpoint['characters']\n",
    "    stoi = checkpoint['stoi']\n",
    "    itos = checkpoint['itos']\n",
    "    \n",
    "    # Create encoding function\n",
    "    encode = lambda s: [stoi[c] for c in s if c in stoi]\n",
    "    decode = lambda l: ''.join([itos[i] for i in l if i in itos])\n",
    "    \n",
    "    # Initialize model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = NanoGPT(len(characters)).to(device)\n",
    "    \n",
    "    # Load model weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode prefix text\n",
    "    encoded_prefix = encode(prefix_text)\n",
    "    if not encoded_prefix:\n",
    "        encoded_prefix = [0]\n",
    "    \n",
    "    # Create tensor\n",
    "    prefix_tensor = torch.tensor([encoded_prefix], dtype=torch.long, device=device)\n",
    "    \n",
    "    # Generate text\n",
    "    generated = model.generate(prefix_tensor, max_tokens)\n",
    "    \n",
    "    # Return decoded text\n",
    "    return decode(generated[0].tolist())\n",
    "\n",
    "# Example usage\n",
    "prefix = \"\"\"\n",
    "GARTH:\n",
    "Oh dear son, why hath thou sainters forsaken us?\n",
    "\n",
    "BRAD:\n",
    "Because thy sainters are destined to despair. Despair for thee supporters and thy foes.\n",
    "\n",
    "GARTH:\n",
    "Thy foes shalt not despair. For they are those whomst benefit from thy despair.\n",
    "\n",
    "BRAD:\n",
    "\"\"\"\n",
    "checkpoint_path = \"saved_models/checkpoint_step_700.pth\"  # Update with actual path\n",
    "generated_text = generate_from_checkpoint(prefix, checkpoint_path)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
